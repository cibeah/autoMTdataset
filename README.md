Experiments: using LLM to create MT datasets

- [x] Add evaluation script
- [ ] Directly split bitexts in train(/dev?)/test
- [ ] Prompt exploration
- [ ] Comparison with best prompt + finetuning
- [ ] Comparison with NMT (from scratch, multilingual, transfer from mBART ?)
